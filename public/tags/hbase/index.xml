<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hbase on DataFibers</title>
    <link>https://datafibers.org/tags/hbase/</link>
    <description>Recent content in Hbase on DataFibers</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://datafibers.org/tags/hbase/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Add Backup Master Node in HBase Cluster</title>
      <link>https://datafibers.org/blog/1/01/01/2013-07-02-hbase-add-backup-master-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://datafibers.org/blog/1/01/01/2013-07-02-hbase-add-backup-master-node/</guid>
      <description>How to add a backup master node to the cluster? There are two ways of doing that.
In One Way  Start the HBase master daemon on the backup master node:
hadoop@master2$ $HBASE_HOME/bin/hbase-daemon.sh start master  From the master log, you will find that the newly started master is waiting to become the next active master:
&amp;gt;org.apache.hadoop.hbase.master.ActiveMasterManager: Another master is the active &amp;gt;master, ip-10-176-201-128.us-west-1.compute.internal, &amp;gt;60000,1328878644330; waiting to become the next active master</description>
    </item>
    
    <item>
      <title>Disable Major Compaction in HBase Cluster</title>
      <link>https://datafibers.org/blog/1/01/01/2013-07-06-hbase-disable-major-compaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://datafibers.org/blog/1/01/01/2013-07-06-hbase-disable-major-compaction/</guid>
      <description>HBase consists of multiple regions. While a region may have several Stores, each holds a single column family. An edit first writes to the hosting region store&amp;rsquo;s in-memory space, which is called MemStore. When the size of MemStore reaches a threshold, it is flushed to StoreFiles on HDFS.
As data increases, there may be many StoreFiles on HDFS, which is not good for its performance. Thus, HBase will automatically pick up a couple of the smaller StoreFiles and rewrite them into a bigger one.</description>
    </item>
    
    <item>
      <title>Rsync for HBase/Hadoop Cluster Deployment</title>
      <link>https://datafibers.org/blog/1/01/01/2012-07-02-rsync-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://datafibers.org/blog/1/01/01/2012-07-02-rsync-deployment/</guid>
      <description>Create a simple rsync script to do HBase/Hadoop deployment
 Create a cluster-deploy.sh script, shown as follows: $ vi cluster-deploy.sh
#!/bin/bash # Sync HBASE_HOME across the cluster. Must run on master using HBase owner user. HBASE_HOME=/usr/local/hbase/current for rs in `cat $HBASE_HOME/conf/regionservers` do echo &amp;quot;Deploying HBase to $rs:&amp;quot; rsync -avz --delete --exclude=logs $HBASE_HOME/ $rs:$HBASE_HOME/ echo sleep 1 done echo &amp;quot;Done&amp;quot;  Run the script as the user who starts Hadoop/HBase on the master node:</description>
    </item>
    
  </channel>
</rss>