<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kafka on DataFibers</title>
    <link>https://datafibers.org/tags/kafka/</link>
    <description>Recent content in Kafka on DataFibers</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Oct 2017 13:50:46 +0200</lastBuildDate>
    
	<atom:link href="https://datafibers.org/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Apache Kafka Overview</title>
      <link>https://datafibers.org/blog/2017/10/05/2017-10-05-apache-kafka-overview/</link>
      <pubDate>Thu, 05 Oct 2017 13:50:46 +0200</pubDate>
      
      <guid>https://datafibers.org/blog/2017/10/05/2017-10-05-apache-kafka-overview/</guid>
      <description>The big data processing started by focusing on the batch processing. Distributed data storage and querying tools like MapReduce, Hive, and Pig were all designed to process data in batches rather than continuously. Recently enterprises have discovered the power of analyzing and processing data and events as they happen instead of batches. Most traditional messaging systems, such as RabbitMq, neither scale up to handle big data in realtime nor use friendly with big data ecosystem.</description>
    </item>
    
  </channel>
</rss>