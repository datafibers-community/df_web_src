<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta charset="utf-8">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Hadoop</title>
  <meta name="author" content="" />

  
  <meta name="keywords" content="devows, hugo, go">	
  

  
  <meta name="description" content="Site template made by devcows using hugo">	
  

  <meta name="generator" content="Hugo 0.36" />

  <link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>

  
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  
  <link href="https://datafibers.orgcss/animate.css" rel="stylesheet">

  
  
    <link href="https://datafibers.orgcss/style.blue.css" rel="stylesheet" id="theme-stylesheet">
  


  
  <link href="https://datafibers.orgcss/custom.css" rel="stylesheet">

  
  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
  <link rel="shortcut icon" href="https://datafibers.orgimg/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" href="https://datafibers.orgimg/apple-touch-icon.png" />
  

  <link href="https://datafibers.orgcss/owl.carousel.css" rel="stylesheet">
  <link href="https://datafibers.orgcss/owl.theme.css" rel="stylesheet">

  <link rel="alternate" href="https://datafibers.org/index.xml" type="application/rss+xml" title="DataFibers">

  
  <meta property="og:title" content="Hadoop" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="/tags/hadoop//" />
  <meta property="og:image" content="img/logo.png" />

</head>


  <body>

    <div id="all">

        <header>

          <div class="navbar-affixed-top" data-spy="affix" data-offset-top="200">

    <div class="navbar navbar-default yamm" role="navigation" id="navbar">

        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="https://datafibers.org">
                    <img src="https://datafibers.orgimg/logo.png" alt="Hadoop logo" class="hidden-xs hidden-sm">
                    <img src="https://datafibers.orgimg/logo-small.png" alt="Hadoop logo" class="visible-xs visible-sm">
                    <span class="sr-only">Hadoop - go to homepage</span>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                      <span class="sr-only">Toggle Navigation</span>
                        <i class="fa fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                  
                  <li class="dropdown">
                    
                    <a href="/">Home</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="https://github.com/datafibers-community/df_data_service/releases">Download</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/community/">Community</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/blog/">Blog</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/training/">Training</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/contact/">Contact</a>
                    
                  </li>
                  
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">

                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">

                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>

                </span>
                    </div>
                </form>

            </div>
            

        </div>
    </div>
    

</div>




        </header>

        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>Hadoop</h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            <div class="container">
                <div class="row">
                    

                    <div class="col-md-9" id="blog-listing-medium">

                        
                        
                        <section class="post">
                            <div class="row">
                                <div class="col-md-4">
                                  <div class="image">
                                      <a href="https://datafibers.org/blog/2018/01/10/2018-01-10-reviews-big-data/">
                                          
                                          <img src="https://datafibers.org/img/banners/book_reviews.jpg" class="img-responsive" alt="">
                                          
                                      </a>
                                  </div>
                                </div>
                                <div class="col-md-8">
                                    <h2><a href="https://datafibers.org/blog/2018/01/10/2018-01-10-reviews-big-data/">Big Data Books Reviews</a></h2>
                                    <div class="clearfix">
                                        <p class="author-category">
                                          
                                          
                                          
                                          in <a href="https://datafibers.orgcategories/review">review</a>
                                          
                                          

                                        </p>
                                        <p class="date-comments">
                                            <a href="https://datafibers.org/blog/2018/01/10/2018-01-10-reviews-big-data/"><i class="fa fa-calendar-o"></i> January 10, 2018</a>
                                        </p>
                                    </div>
                                    <p class="intro">Learning Spark SQL  Level Ent.
 Level Mid.
 Level Adv.  Published in Sep. 2017. Start reading it.

Learning Apache Flink  Level Ent. Level Mid.  There are very few books about Apache Flink. Besides offical document, this is a good one for people who wants to know Flink quicker. This book, published in the earlier of 2017, covers most of core topics for Flink with examples.</p>
                                    <p class="read-more"><a href="https://datafibers.org/blog/2018/01/10/2018-01-10-reviews-big-data/" class="btn btn-template-main">Continue reading</a>
                                    </p>
                                </div>
                            </div>
                        </section>
                        
                        <section class="post">
                            <div class="row">
                                <div class="col-md-4">
                                  <div class="image">
                                      <a href="https://datafibers.org/blog/1/01/01/2015-03-15-apache-hive-essentials-published/">
                                          
                                          <img src="https://datafibers.orgimg/placeholder.png" class="img-responsive" alt="">
                                          
                                      </a>
                                  </div>
                                </div>
                                <div class="col-md-8">
                                    <h2><a href="https://datafibers.org/blog/1/01/01/2015-03-15-apache-hive-essentials-published/">Apache Hive Essentials Published</a></h2>
                                    <div class="clearfix">
                                        <p class="author-category">
                                          
                                          

                                        </p>
                                        <p class="date-comments">
                                            <a href="https://datafibers.org/blog/1/01/01/2015-03-15-apache-hive-essentials-published/"><i class="fa fa-calendar-o"></i> January 1, 0001</a>
                                        </p>
                                    </div>
                                    <p class="intro">Finally, I made it. I got it published after working for 6 monthes.
Apache Hive Essentials  My very first book Also the first book on Apache Hive 1.0.0 in the world  Check it out here</p>
                                    <p class="read-more"><a href="https://datafibers.org/blog/1/01/01/2015-03-15-apache-hive-essentials-published/" class="btn btn-template-main">Continue reading</a>
                                    </p>
                                </div>
                            </div>
                        </section>
                        
                        <section class="post">
                            <div class="row">
                                <div class="col-md-4">
                                  <div class="image">
                                      <a href="https://datafibers.org/blog/1/01/01/2015-02-02-data-lake-stages/">
                                          
                                          <img src="https://datafibers.orgimg/placeholder.png" class="img-responsive" alt="">
                                          
                                      </a>
                                  </div>
                                </div>
                                <div class="col-md-8">
                                    <h2><a href="https://datafibers.org/blog/1/01/01/2015-02-02-data-lake-stages/">Data Lake Stages</a></h2>
                                    <div class="clearfix">
                                        <p class="author-category">
                                          
                                          

                                        </p>
                                        <p class="date-comments">
                                            <a href="https://datafibers.org/blog/1/01/01/2015-02-02-data-lake-stages/"><i class="fa fa-calendar-o"></i> January 1, 0001</a>
                                        </p>
                                    </div>
                                    <p class="intro">Edd has post a very impressive blog about how Hadoop ecosystem influence the data lake in enterprise recently. It discussed about the four following stages when enterprise&rsquo;s data evolution to the dream of data lake. I also share some of mine as addition.
Stage 1 - Life Before Hadoop In this stage, the enterprise data architecture has following characteristics.
 Applications stand alone with their databases Some applications contribute data to a data warehouse Analysts run reporting and analytics in data warehouse  What&rsquo;s more:</p>
                                    <p class="read-more"><a href="https://datafibers.org/blog/1/01/01/2015-02-02-data-lake-stages/" class="btn btn-template-main">Continue reading</a>
                                    </p>
                                </div>
                            </div>
                        </section>
                        
                        <section class="post">
                            <div class="row">
                                <div class="col-md-4">
                                  <div class="image">
                                      <a href="https://datafibers.org/blog/1/01/01/2013-06-03-hadoop-counter/">
                                          
                                          <img src="https://datafibers.orgimg/placeholder.png" class="img-responsive" alt="">
                                          
                                      </a>
                                  </div>
                                </div>
                                <div class="col-md-8">
                                    <h2><a href="https://datafibers.org/blog/1/01/01/2013-06-03-hadoop-counter/">Hadoop Counter</a></h2>
                                    <div class="clearfix">
                                        <p class="author-category">
                                          
                                          

                                        </p>
                                        <p class="date-comments">
                                            <a href="https://datafibers.org/blog/1/01/01/2013-06-03-hadoop-counter/"><i class="fa fa-calendar-o"></i> January 1, 0001</a>
                                        </p>
                                    </div>
                                    <p class="intro">hadoop counter is to help developers and users to have overall status of running jobs. There are three type of counters, MapReduce related, File systems related, and job related. The details can be seen from http://master:50030/jobdetails.jsp
Except internal counters, hadoop also offers customize counters. There are two ways to do that.
1. Static Definition You can use enumiate classs to create counters
Context context... //Enum class refers to groupName，Enum class type refers to counterName context.</p>
                                    <p class="read-more"><a href="https://datafibers.org/blog/1/01/01/2013-06-03-hadoop-counter/" class="btn btn-template-main">Continue reading</a>
                                    </p>
                                </div>
                            </div>
                        </section>
                        
                        <section class="post">
                            <div class="row">
                                <div class="col-md-4">
                                  <div class="image">
                                      <a href="https://datafibers.org/blog/1/01/01/2013-05-07-hadoop-customize-data-type/">
                                          
                                          <img src="https://datafibers.orgimg/placeholder.png" class="img-responsive" alt="">
                                          
                                      </a>
                                  </div>
                                </div>
                                <div class="col-md-8">
                                    <h2><a href="https://datafibers.org/blog/1/01/01/2013-05-07-hadoop-customize-data-type/">Hadoop Customize Data Type</a></h2>
                                    <div class="clearfix">
                                        <p class="author-category">
                                          
                                          

                                        </p>
                                        <p class="date-comments">
                                            <a href="https://datafibers.org/blog/1/01/01/2013-05-07-hadoop-customize-data-type/"><i class="fa fa-calendar-o"></i> January 1, 0001</a>
                                        </p>
                                    </div>
                                    <p class="intro">Customize Data Type - As Value To create a customized data type used as a value, the data type must implement the org.apache.hadoop.io.Writable interface which consists of the two methods, readFields() and write()
 void readFields(DataInput in) : Deserialize the fields of this object from in. [void write(DataOutput out)](http://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/Writable.html#write(java.io.DataOutput) : Serialize the fields of this object to out.  Note:
 In case you are adding a custom constructor to your custom Writable class, make sure to retain the default empty constructor.</p>
                                    <p class="read-more"><a href="https://datafibers.org/blog/1/01/01/2013-05-07-hadoop-customize-data-type/" class="btn btn-template-main">Continue reading</a>
                                    </p>
                                </div>
                            </div>
                        </section>
                        
                        <section class="post">
                            <div class="row">
                                <div class="col-md-4">
                                  <div class="image">
                                      <a href="https://datafibers.org/blog/1/01/01/2015-06-21-hadoop-streaming/">
                                          
                                          <img src="https://datafibers.orgimg/placeholder.png" class="img-responsive" alt="">
                                          
                                      </a>
                                  </div>
                                </div>
                                <div class="col-md-8">
                                    <h2><a href="https://datafibers.org/blog/1/01/01/2015-06-21-hadoop-streaming/">Hadoop Streaming</a></h2>
                                    <div class="clearfix">
                                        <p class="author-category">
                                          
                                          

                                        </p>
                                        <p class="date-comments">
                                            <a href="https://datafibers.org/blog/1/01/01/2015-06-21-hadoop-streaming/"><i class="fa fa-calendar-o"></i> January 1, 0001</a>
                                        </p>
                                    </div>
                                    <p class="intro">1. Streaming Overview Hadoop Streaming is a generic API which allows writing Mappers and Reduces in any language.
 Develop MapReduce jobs in practically any language Uses Unix Streams as communication mechanism between Hadoop and your code Any language that can read standard input and write are supported  Few good use-cases:
 Text processing - scripting languages do well in text analysis Utilities and/or expertise in languages other than Java  2.</p>
                                    <p class="read-more"><a href="https://datafibers.org/blog/1/01/01/2015-06-21-hadoop-streaming/" class="btn btn-template-main">Continue reading</a>
                                    </p>
                                </div>
                            </div>
                        </section>
                        
                        <section class="post">
                            <div class="row">
                                <div class="col-md-4">
                                  <div class="image">
                                      <a href="https://datafibers.org/blog/1/01/01/2014-06-01-hive-and-hadoop-exceptions/">
                                          
                                          <img src="https://datafibers.orgimg/placeholder.png" class="img-responsive" alt="">
                                          
                                      </a>
                                  </div>
                                </div>
                                <div class="col-md-8">
                                    <h2><a href="https://datafibers.org/blog/1/01/01/2014-06-01-hive-and-hadoop-exceptions/">Hive and Hadoop Exceptions</a></h2>
                                    <div class="clearfix">
                                        <p class="author-category">
                                          
                                          

                                        </p>
                                        <p class="date-comments">
                                            <a href="https://datafibers.org/blog/1/01/01/2014-06-01-hive-and-hadoop-exceptions/"><i class="fa fa-calendar-o"></i> January 1, 0001</a>
                                        </p>
                                    </div>
                                    <p class="intro">I installed Hive 1.0.0 on Hadoop 1.2.1. When I try to enter the Hive CLI, it reports following exceptions
org.apache.hadoop.hive.ql.metadata.HiveException:java.io.IOException:Filesystem closed  According to the search here, the mainly reason for this is that when multiple nodes read HFDS files if one node is offline, it will throw such exception when the other nodes are still reading the data cached. There are two ways to resolve this.
 Turn off JVM reuse  &lt;property&gt; &lt;name&gt;mapred.</p>
                                    <p class="read-more"><a href="https://datafibers.org/blog/1/01/01/2014-06-01-hive-and-hadoop-exceptions/" class="btn btn-template-main">Continue reading</a>
                                    </p>
                                </div>
                            </div>
                        </section>
                        
                        <section class="post">
                            <div class="row">
                                <div class="col-md-4">
                                  <div class="image">
                                      <a href="https://datafibers.org/blog/1/01/01/2015-02-12-hive-and-hadoop-exceptions/">
                                          
                                          <img src="https://datafibers.orgimg/placeholder.png" class="img-responsive" alt="">
                                          
                                      </a>
                                  </div>
                                </div>
                                <div class="col-md-8">
                                    <h2><a href="https://datafibers.org/blog/1/01/01/2015-02-12-hive-and-hadoop-exceptions/">Hive and Hadoop Exceptions</a></h2>
                                    <div class="clearfix">
                                        <p class="author-category">
                                          
                                          

                                        </p>
                                        <p class="date-comments">
                                            <a href="https://datafibers.org/blog/1/01/01/2015-02-12-hive-and-hadoop-exceptions/"><i class="fa fa-calendar-o"></i> January 1, 0001</a>
                                        </p>
                                    </div>
                                    <p class="intro">I installed Hive 1.0.0 on Hadoop 1.2.1. When I try to enter the Hive CLI, it reports following exceptions
org.apache.hadoop.hive.ql.metadata.HiveException:java.io.IOException:Filesystem closed  According to the search here, the mainly reason for this is that when multiple nodes read HFDS files if one node is offline, it will throw such exception when the other nodes are still reading the data cached. There are two ways to resolve this.
 Turn off JVM reuse  &lt;property&gt; &lt;name&gt;mapred.</p>
                                    <p class="read-more"><a href="https://datafibers.org/blog/1/01/01/2015-02-12-hive-and-hadoop-exceptions/" class="btn btn-template-main">Continue reading</a>
                                    </p>
                                </div>
                            </div>
                        </section>
                        
                        <section class="post">
                            <div class="row">
                                <div class="col-md-4">
                                  <div class="image">
                                      <a href="https://datafibers.org/blog/1/01/01/2014-11-23-move-to-the-spark/">
                                          
                                          <img src="https://datafibers.orgimg/placeholder.png" class="img-responsive" alt="">
                                          
                                      </a>
                                  </div>
                                </div>
                                <div class="col-md-8">
                                    <h2><a href="https://datafibers.org/blog/1/01/01/2014-11-23-move-to-the-spark/">Moving to the Spark</a></h2>
                                    <div class="clearfix">
                                        <p class="author-category">
                                          
                                          

                                        </p>
                                        <p class="date-comments">
                                            <a href="https://datafibers.org/blog/1/01/01/2014-11-23-move-to-the-spark/"><i class="fa fa-calendar-o"></i> January 1, 0001</a>
                                        </p>
                                    </div>
                                    <p class="intro">It has been a while that the blog is now updated since 2014 is a ready busy year. After I almost completed my first book recently, I think it is the right time to start new journey in big data for real time processing.
Big data ecosystem has great changes over the past two years. The speed of big data processing becomes the hot topic over the past year. When Hadoop enter the area of Yarn, it becomes more like a distribute computing infrastructure.</p>
                                    <p class="read-more"><a href="https://datafibers.org/blog/1/01/01/2014-11-23-move-to-the-spark/" class="btn btn-template-main">Continue reading</a>
                                    </p>
                                </div>
                            </div>
                        </section>
                        
                        <section class="post">
                            <div class="row">
                                <div class="col-md-4">
                                  <div class="image">
                                      <a href="https://datafibers.org/blog/1/01/01/2012-07-02-rsync-deployment/">
                                          
                                          <img src="https://datafibers.orgimg/placeholder.png" class="img-responsive" alt="">
                                          
                                      </a>
                                  </div>
                                </div>
                                <div class="col-md-8">
                                    <h2><a href="https://datafibers.org/blog/1/01/01/2012-07-02-rsync-deployment/">Rsync for HBase/Hadoop Cluster Deployment</a></h2>
                                    <div class="clearfix">
                                        <p class="author-category">
                                          
                                          

                                        </p>
                                        <p class="date-comments">
                                            <a href="https://datafibers.org/blog/1/01/01/2012-07-02-rsync-deployment/"><i class="fa fa-calendar-o"></i> January 1, 0001</a>
                                        </p>
                                    </div>
                                    <p class="intro">Create a simple rsync script to do HBase/Hadoop deployment
 Create a cluster-deploy.sh script, shown as follows: $ vi cluster-deploy.sh
#!/bin/bash # Sync HBASE_HOME across the cluster. Must run on master using HBase owner user. HBASE_HOME=/usr/local/hbase/current for rs in `cat $HBASE_HOME/conf/regionservers` do echo &quot;Deploying HBase to $rs:&quot; rsync -avz --delete --exclude=logs $HBASE_HOME/ $rs:$HBASE_HOME/ echo sleep 1 done echo &quot;Done&quot;  Run the script as the user who starts Hadoop/HBase on the master node:</p>
                                    <p class="read-more"><a href="https://datafibers.org/blog/1/01/01/2012-07-02-rsync-deployment/" class="btn btn-template-main">Continue reading</a>
                                    </p>
                                </div>
                            </div>
                        </section>
                        

                        <ul class="pager">
                            
                            <li class="previous disabled"><a href="#">&larr; Newer</a></li>
                            

                            
                            <li class="next"><a href="https://datafibers.org/tags/hadoop/page/2/">Older &rarr;</a></li>
                            
                        </ul>
                    </div>
                    

                    

                    

                    <div class="col-md-3">

                        

                        

<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Search</h3>
    </div>

    <div class="panel-body">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" role="search">
            <div class="input-group">
                <input type="search" name="q" class="form-control" placeholder="Search">
                <input type="hidden" name="sitesearch" value="https://datafibers.org">
                <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>
                </span>
            </div>
        </form>
    </div>
</div>







<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Categories</h3>
    </div>

    <div class="panel-body">
        <ul class="nav nav-pills nav-stacked">
            
            <li><a href="https://datafibers.orgcategories/article">article (6)</a>
            </li>
            
            <li><a href="https://datafibers.orgcategories/programming">programming (2)</a>
            </li>
            
            <li><a href="https://datafibers.orgcategories/pseudo">pseudo (1)</a>
            </li>
            
            <li><a href="https://datafibers.orgcategories/release">release (3)</a>
            </li>
            
            <li><a href="https://datafibers.orgcategories/review">review (1)</a>
            </li>
            
            <li><a href="https://datafibers.orgcategories/tutorial">tutorial (1)</a>
            </li>
            
        </ul>
    </div>
</div>








<div class="panel sidebar-menu">
    <div class="panel-heading">
      <h3 class="panel-title">Tags</h3>
    </div>

    <div class="panel-body">
        <ul class="tag-cloud">
            
            <li><a href="https://datafibers.orgtags/bigdata"><i class="fa fa-tags"></i> bigdata</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/datafibers"><i class="fa fa-tags"></i> datafibers</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/datamining"><i class="fa fa-tags"></i> datamining</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/git"><i class="fa fa-tags"></i> git</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/go"><i class="fa fa-tags"></i> go</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/hadoop"><i class="fa fa-tags"></i> hadoop</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/hbase"><i class="fa fa-tags"></i> hbase</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/hive"><i class="fa fa-tags"></i> hive</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/hugo"><i class="fa fa-tags"></i> hugo</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/kafka"><i class="fa fa-tags"></i> kafka</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/maven"><i class="fa fa-tags"></i> maven</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/pig"><i class="fa fa-tags"></i> pig</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/programming"><i class="fa fa-tags"></i> programming</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/scala"><i class="fa fa-tags"></i> scala</a>
            </li>
            
            <li><a href="https://datafibers.orgtags/spark"><i class="fa fa-tags"></i> spark</a>
            </li>
            
        </ul>
    </div>
</div>






                        

                    </div>
                    

                    

                </div>
                
            </div>
            
        </div>
        

        <footer id="footer">
    <div class="container">

        
        <div class="col-md-4 col-sm-6">
            <h4>About us</h4>

            DataFibers are expertises by applying its cutting edge big data technologies and solutions on enterprise big data centric use cases.

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

        <div class="col-md-4 col-sm-6">

             
            <h4>Recent posts</h4>

            <div class="blog-entries">
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="https://datafibers.org/blog/2018/02/02/2018-02-02-hive-get-max-min-value-rows/">
                          
                            <img src="https://datafibers.org/img/banners/maxmin.jpg" class="img-responsive" alt="Hive Get the Max/Min">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="https://datafibers.org/blog/2018/02/02/2018-02-02-hive-get-max-min-value-rows/">Hive Get the Max/Min</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="https://datafibers.org/blog/2018/01/10/2018-01-10-reviews-big-data/">
                          
                            <img src="https://datafibers.org/img/banners/book_reviews.jpg" class="img-responsive" alt="Big Data Books Reviews">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="https://datafibers.org/blog/2018/01/10/2018-01-10-reviews-big-data/">Big Data Books Reviews</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="https://datafibers.org/blog/2017/12/22/2017-12-22-df-winter-release/">
                          
                            <img src="https://datafibers.org/img/banners/df_release.jpg" class="img-responsive" alt="2017 Winter Release">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="https://datafibers.org/blog/2017/12/22/2017-12-22-df-winter-release/">2017 Winter Release</a></h5>
                    </div>
                </div>
                
            </div>

            <hr class="hidden-md hidden-lg">
             

        </div>
        

        
        <div class="col-md-4 col-sm-6">

          <h4>Contact</h4>

            <strong>DataFibers.</strong>
        <br>7030 Woodbine Avenue,
        <br>L3R 6G2
        <br>Ontario, Markham
        <br>
        <strong>Canada</strong>
      </p>
      


            <a href="/contact" class="btn btn-small btn-template-main">Go to contact page</a>

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

    </div>
    
</footer>







<div id="copyright">
    <div class="container">
        <div class="col-md-12">
            
            <p class="pull-left">Copyright (c) 2018, DataFibers all rights reserved.</p>
            
            <p class="pull-right">
              Template by <a href="http://bootstrapious.com/free-templates">Bootstrapious</a>.
              

              Powered by <a href="https://gohugo.io/">Hugo</a>
            </p>
        </div>
    </div>
</div>





    </div>
    

    
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-40213017-3', 'auto');
ga('send', 'pageview');
</script>

<script src="//code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>

<script src="//maps.googleapis.com/maps/api/js?key=AIzaSyCksU3IZTuUK6fA-doQUfQ4KcYm7mB_vlk&v=3.exp"></script>

<script src="https://datafibers.orgjs/hpneo.gmaps.js"></script>
<script src="https://datafibers.orgjs/gmaps.init.js"></script>
<script src="https://datafibers.orgjs/front.js"></script>


<script src="https://datafibers.orgjs/owl.carousel.min.js"></script>


  </body>
</html>
